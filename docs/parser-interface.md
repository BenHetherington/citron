---
title: "The Parser Interface"
permalink: /parser-interface/
---

_This documentation page is not fully baked yet._

# The Parser Interface

## Code files

Here's a quick overview of the Swift files we would compile when
building a parser using Citron:

 1. `CitronParser.swift` from the Citron code base

    This defines the [`CitronParser`](api/CitronParser/) protocol. This
    protocol implements the following methods:

      - [`consume(token:, code:)`]

      - [`endParsing()`]

 2. The parser generated by Citron

    The parser code generated by Citron contains a parser class that
    implements the `CitronParser` protocol. The name of the parser class
    is `Parser` by default, but [can be
    changed](../grammar-file/#class_name).

    The methods defined on the `CitronParser` protocol can be called on
    this class to parse an input:

      - [`consume(token:, code:)`]

        Consume one token whose semantic value is `token` and token code
        is `code`.

        This method should be called multiple times to pass a sequence
        of tokens to the parser. Typically, a separate tokenization
        stage (like `CitronLexer`) would generate this sequence of
        tokens.

      - [`endParsing()`]

        This method tells the parser that there are no more tokens to
        consume, and signifies the end of input.

 3. `CitronLexer.swift` from the Citron code base, if we're using
    Citron's lexer

    This defines the `CitronLexer` class, which is a simple lexer.
    It provides the following methods:

      - `init(rules:)`

        Create the lexer with a bunch of lexing rules.

      - `tokenize(string:, onFound:)`

        Tokenize the `string`, and call the `onFound` block when tokens
        matching the rules are found.

 4. The code that drives the parsing

    This code should use a tokenizer (like `CitronLexer`) to create tokens from
    the input and pass that on the the parser using the
    `consume(token:, code:)` and `endParsing()` methods.

[`CitronParser`]: api/CitronParser/
[`consume(token:, code:)`]: api/CitronParser/#consumetoken-citrontoken-tokencode-citrontokencode
[`endParsing()`]: api/CitronParser/#endparsing

### Error handling

Both `consume(token:code:)` and `endParsing()` are throwing methods.
They throw when an input token at a certain position is inconsistent
with the grammar, or when the input ends prematurely.

Moreover, we can throw errors from within a rule's code block and those
throws would propagate up to one of the two parsing methods.

## The lexer interface

Citron offers a simple lexer that can tokenize an input string.

We give the lexer a series of rules with either string or regular
expression patterns. The token data that the lexer should output can be
of an arbitrary type, so the lexer is defined as a generic type, with
the token data as a type parameter. For each string pattern, we should
associate it with the token data that should be output, and for each
regular expression pattern, we should provide a closure that returns the
token data from the matched string.

## Examples

A few examples of how Citron is used for parsing can be found in the
["examples" folder][eg] in the project repository.

[eg]: https://github.com/roop/citron/tree/master/examples/

